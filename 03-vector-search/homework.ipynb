{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7da6285-4023-4ccd-83f5-c373f9c01798",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb37cdf-7c7f-40c2-94c0-55c694e9b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01e2b9a-eb84-44e2-a003-f4f94f4682bc",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddings model\n",
    "\n",
    "First, we will get the embeddings model multi-qa-distilbert-cos-v1 from the [Sentence Transformer library](https://www.sbert.net/docs/sentence_transformer/pretrained_models.html#model-overview)\n",
    "\n",
    "What's the first value of the resulting vector?\n",
    "* **0.07**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c3b00e7-cc95-4923-ac97-0839183351db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.13/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('multi-qa-distilbert-cos-v1')\n",
    "user_question = \"I just discovered the course. Can I still join it?\"\n",
    "v = model.encode(user_question)\n",
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b031696-8072-4d80-8439-c71403a9f53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.078222655"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2378e46a-5602-4f80-8036-cf61b15db6be",
   "metadata": {},
   "source": [
    "## Q2. Creating the embeddings\n",
    "\n",
    "Now for each document, we will create an embedding for both question and answer fields.\n",
    "\n",
    "What's the shape of X? `(X.shape)`. Include the parantheses.\n",
    "* **(375, 768)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be083a6-a5b6-4c14-bc62-45735a36d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/documents-with-ids.json'\n",
    "docs_url = f'{base_url}/{relative_url}?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b4c745-d2ae-4feb-a547-58420aff3894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_documents(doc):\n",
    "    if doc['course'] == \"machine-learning-zoomcamp\":\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "documents_iterator = filter(filter_documents, documents)\n",
    "filtered_documents = list(documents_iterator)\n",
    "len(filtered_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cff52e4-8938-4f35-a64c-942875c01ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 375/375 [01:05<00:00,  5.73it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "for doc in tqdm(filtered_documents):\n",
    "    qa_text = f\"{doc['question']} {doc['text']}\"\n",
    "    emb = model.encode(qa_text)\n",
    "    doc['qa_vector'] = emb.tolist()\n",
    "    embeddings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd428898-064e-46a3-a931-cc7278e1034f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(375, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(embeddings)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640bbe2d-7873-408f-9316-8b9a2900fb94",
   "metadata": {},
   "source": [
    "## Q3. Search\n",
    "\n",
    "We have the embeddings and the query vector. Now let's compute the cosine similarity between the vector from Q1 (let's call it `v`) and the matrix from Q2.\n",
    "\n",
    "The vectors returned from the embedding model are already normalized (you can check it by computing a dot product of a vector with itself - it should return something very close to 1.0). This means that in order to compute the coside similarity, it's sufficient to multiply the matrix `X` by the vector `v`:\n",
    "\n",
    "```python\n",
    "scores = X.dot(v)\n",
    "```\n",
    "\n",
    "What's the highest score in the results?\n",
    "* **0.65**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf2c6ae-2887-43f3-8c03-c6aa8f613e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6506573"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = X.dot(v)\n",
    "max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e401b-8ace-47af-809d-4ad01dbe3bd6",
   "metadata": {},
   "source": [
    "## Q4. Hit-rate for our search engine\n",
    "\n",
    "Let's evaluate the performance of our own search engine. We will use the hitrate metric for evaluation.\n",
    "\n",
    "Now use the code from the module to calculate the hitrate of `VectorSearchEngine` with `num_results=5`.\n",
    "\n",
    "What did you get?\n",
    "* **0.33**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c9b047-66f1-4a39-8bb9-57254187dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class VectorSearchEngine():\n",
    "    def __init__(self, documents, embeddings):\n",
    "        self.documents = documents\n",
    "        self.embeddings = embeddings\n",
    "\n",
    "    def search(self, v_query, num_results=10):\n",
    "        scores = self.embeddings.dot(v_query)\n",
    "        idx = np.argsort(-scores)[:num_results]\n",
    "        return [self.documents[i] for i in idx]\n",
    "\n",
    "def hit_rate(relevance_total):\n",
    "    count = 0\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            count += 1\n",
    "\n",
    "    return count / len(relevance_total)\n",
    "\n",
    "base_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main'\n",
    "relative_url = '03-vector-search/eval/ground-truth-data.csv'\n",
    "ground_truth_url = f'{base_url}/{relative_url}?raw=1'\n",
    "\n",
    "df_ground_truth = pd.read_csv(ground_truth_url)\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32e2f29c-8a64-4e0c-a03c-7b982204cfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1830/1830 [00:00<00:00, 18305.73it/s]\n"
     ]
    }
   ],
   "source": [
    "search_engine = VectorSearchEngine(documents=filtered_documents, embeddings=X)\n",
    "\n",
    "relevance_total = []\n",
    "for q in tqdm(ground_truth):\n",
    "    doc_id = q['document']\n",
    "    results = search_engine.search(v, num_results=5)\n",
    "    relevance = [d['id'] == doc_id for d in results]\n",
    "    relevance_total.append(relevance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba11bf5c-cf33-4a94-ad0c-5df5c27c15c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01366120218579235"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hit_rate(relevance_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dbb0cf-7d69-46c2-b8d8-9724304b6840",
   "metadata": {},
   "source": [
    "## Q5. Indexing with Elasticsearch\n",
    "\n",
    "Now let's index these documents with elasticsearch:\n",
    "* Create the index with the same settings as in the module (but change the dimensions)\n",
    "* Index the embeddings (note: you've already computed them)\n",
    "  \n",
    "After indexing, let's perform the search of the same query from Q1.\n",
    "\n",
    "What's the ID of the document with the highest score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f045f65-7e46-45a3-bf99-9c789bc96a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': '38fbeb184f3f', 'cluster_name': 'docker-cluster', 'cluster_uuid': '4gE-8p9lSpe_fzCPNYtLKA', 'version': {'number': '8.4.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73', 'build_date': '2022-10-04T07:17:24.662462378Z', 'build_snapshot': False, 'lucene_version': '9.3.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200', request_timeout=60, max_retries=10, retry_on_timeout=True)\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d401c1fd-f9e6-4cd0-9d66-f7144d6df824",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"qa_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 375,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98093cab-69c9-4ec5-9df4-70ed003f055f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': False, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"course-questions\"\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c2e7f-3257-4e68-91da-17baad7142b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                     | 0/375 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(filtered_documents):\n",
    "    try:\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df03af34-f36f-4869-9fc2-a8bdd9f0c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = es_client.search(index=index_name, body=v)\n",
    "result[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7a4af3-0065-4957-9734-051e976c7b6d",
   "metadata": {},
   "source": [
    "## Q6. Hit-rate for Elasticsearch\n",
    "\n",
    "The search engine we used in Q4 computed the similarity between the query and ALL the vectors in our database. Usually this is not practical, as we may have a lot of data.\n",
    "\n",
    "Elasticsearch uses approximate techniques to make it faster.\n",
    "\n",
    "Let's evaluate how worse the results are when we switch from exact search (as in Q4) to approximate search with Elastic.\n",
    "\n",
    "What's hitrate for our dataset for Elastic?\n",
    "* **0.73**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
